{
    "contents" : "rm(list = ls())\nlibrary(shiny)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(xts)\nlibrary(xlsx)\n\n\n## dealing with NA's\n## function, that imputing NA's with median vaues\nimputeMedian <- function(df, impute.var) {\n  data <- df\n  data[which(is.na(data[, impute.var]) == TRUE), impute.var] = \n    median(data[which(is.na(data[, impute.var]) == FALSE), impute.var])\n  return (data)\n}\n\n## dealing with NA's\n## function, that imputing NA's with mean vaues in each group\nimputeMean <- function(impute.var, filter.var, var.levels) {\n  for (v in var.levels) {\n    impute.var[ which(filter.var == v)] <- impute(impute.var[\n      which(filter.var == v)\n      ], fun = mean)\n  }\n  return (impute.var)\n}\n\n# predicting price (from self-written tsauxfunc package)\npredict_price <- function(cur_ts, h, n) {\n  tryCatch(\n    {\n      print(\"Building Holt-Winters model...\")\n      current_model <- HoltWinters(cur_ts)\n      return (predict(current_model, n = h)[n])\n    }, error = function(cond) {\n      message(\"Holt-Winters model optimization failed to converge!\")\n      print(\"Starting calculation with default algorithm...\")\n      print(\"Algorithm: prediction = prev_month_cur_year/\n            (prev_month_prev_year*cur_month_prev_year)\")\n      return (last(lag(cur_ts)) / last(lag(cur_ts, 13)) * last(lag(cur_ts, 12)))\n    }\n  )\n}\n\n# predicting price for objects with short history\n# (from self-written tsauxfunc package)\npredict_price_short <- function(cur_ts, nsteps, n) {\n  require(forecast)\n  tryCatch(\n    {\n      print(\"Building Arima model...\")\n      current_model <- auto.arima(cur_ts)\n      return (forecast(current_model, h = nsteps)$mean[n])\n    }, error = function(cond) {\n      message(\"Arima model optimization failed to converge!\")\n      message(\"MA prediction failed!\")\n      print(\"Calculating simple mean...\")\n      return (mean(cur_ts))\n    }\n  )\n}\n\n# creating list of DPGs with the siaze of it's history (in months) \n# (from self-written tsauxfunc package)\nrangeByHistorySize <- function(dataset, keyFactor) {\n  #creating output df\n  historyRanks <- data.frame(FactorLevel=as.character(), \n                             HistorySize=as.integer())\n  # for each unique value of the factor var do...\n  for (i in levels(keyFactor)) {\n    #historyRow <- data.frame(FactorLevel = i, HistorySize = nrow(dataset[which(dataset$keyFactor == i), ]))\n    historyRanks <- rbind(historyRanks, data.frame(FactorLevel = i, \n                                                   HistorySize = nrow(dataset[which(keyFactor == i), ])))\n  }\n  return (historyRanks[order(-historyRanks$HistorySize), ])\n}\n\n# keeping only those objects which exists in the (n-1) month\n# (from self-written tsauxfunc package)\nfilterActuals <- function(df, date_var, group_var, cur_date) {\n  actualDPGs <- unique(subset(df, df[, date_var] == as.Date(cur_date), \n                              select = group_var))\n  res = merge(df, actualDPGs, by = group_var)\n  return(res)\n}\n\n# converting dataframe to timeseries\n# (from self-written tsauxfunc package)\ntoTimeSeries <- function(df, date_var, freq, start_date) {\n  require(xts)\n  as_ts <- xts(df[ , !colnames(df) %in% c(date_var)], order.by = df[ , date_var])\n  result <- ts(as_ts, frequency = freq, start = as.Date(start_date))\n  return (result)\n}\n\n# Function applies forecasting method to paneled time series with history size \n# more than 21 months\nhwforecast_n_step_fwrd <- function(df, group.var, date.var, target.var, h, n) {\n  require(xts)\n  require(tseries)\n  predictions <- list()\n  # safe copying\n  tbl <- df[, c(group.var , date.var, target.var)]\n  tbl <- tbl[order(tbl[ , group.var], tbl[ , date.var]), ]\n  for (i in unique(tbl[, group.var])) {\n    # partitioning by group_var values\n    one_piece  <- tbl[which(tbl[ , group.var] == i), c(date.var, target.var)]\n    if (nrow(one_piece[which(is.na(one_piece[, target.var]) == TRUE), ]) > 0)\n      # imputing missing values\n      one_piece <- imputeMedian(one_piece, target.var)\n    start_date <- min(one_piece[, date.var])\n    # making a TS object\n    one_piece_ts <- toTimeSeries(one_piece, date.var, 12, start_date)\n    # predicting with Holt-Winters algorithm\n    prediction_hw <- predict_price(one_piece_ts, h, n)\n    # predicting with ARIMA\n    prediction_arima <- predict_price_short(one_piece_ts, h, n)\n    prediction <- mean(c(prediction_hw, prediction_arima))\n    if (prediction < 0) prediction <- prediction_arima\n    predictions[i] <- prediction\n    print(predictions[i])\n  }\n  return (predictions)\n}\n\n# Function applies forecasting method to paneled time series with history size \n# less than 21 months\nshortForecast <- function(df, group.var, date.var, target.var, h, n) {\n  require(TTR)\n  require(xts)\n  require(tseries)\n  predictions <- list()\n  # safe copying\n  tbl <- df[, c(group.var , date.var, target.var)]\n  tbl <- tbl[order(tbl[ , group.var], tbl[ , date.var]), ]\n  for (i in unique(tbl[, group.var])) {\n    # partitioning by group_var values\n    one_piece  <- tbl[which(tbl[ , group.var] == i), c(date.var, target.var)]\n    if (nrow(one_piece[which(is.na(one_piece[, target.var]) == TRUE), ]) > 0)\n      one_piece <- imputeMedian(one_piece, target.var)\n    start_date <- min(one_piece[, date.var])\n    # making a TS object\n    one_piece_ts <- toTimeSeries(one_piece, date.var, 1, start_date)\n    predictions[i] <- predict_price_short(one_piece_ts, h, n)\n    print(predictions[i])\n  }\n  return (predictions)\n}\n\n# data frame for saving forecast-data\nforecasts_to_save <- data.frame(PCODE = character(), REGION = character(), \n                                SVNC_M_FCST = numeric(), SVNC_EE_FCST = numeric(), \n                                stringsAsFactors = FALSE)\n\n# get participant-region table from the last available month data\ngetParticipantsRegions <- function() {\n  res <- svnc_data[svnc_data$TDATE == max(svnc_data$TDATE), \n                   c(\"PCODE\", \"PNAME\", \"REGION_NAME\")]\n}\n\n# gets participant names by there codes\ngetPName <- function(pcd) {\n  if (is.null(pcd))\n    return (\"\")\n  pcode <- pcd\n  pcode_data <- svnc_data[svnc_data$PCODE == pcode, c(\"TDATE\", \"PNAME\")]\n  max_date <- max(pcode_data$TDATE)\n  result <-  unique(pcode_data[which(pcode_data$TDATE == max_date), c(\"PNAME\")])\n  return (result)\n}\n\ngetRegions <- function(pcodes) {\n  \n  res <- svnc_data[svnc_data$PCODE == pcodes, c(\"REGION_NAME\")]\n  return(res)\n}\n\ngetFactParticipant <- function(pcode, reg_name) {\n  data <- svnc_data[svnc_data$PCODE %in% pcode & svnc_data$REGION_NAME %in% reg_name,\n                    c(\"TDATE\", \"PCODE\", \"PNAME\", \"TCODE\", \"REGION_CODE\", \"REGION_NAME\", \n                      \"P_NC_UNREG_AVG\", \"P_VC_UNREG_AVG\", \"PIKE_FACT\", \"VOLUME\")]\n  #data$TDATE <- as.Date(data$TDATE)\n  data$P_R <- paste(data$PCODE, data$REGION_NAME)\n  data$N_COST <- data$P_NC_UNREG_AVG * data$PIKE_FACT\n  data$EE_COST <- data$P_VC_UNREG_AVG * data$VOLUME\n  library(dplyr)\n  dataParticipant <- summarize(group_by(data, TDATE, PNAME, P_R), \n                              SVNC_M = sum(N_COST)/sum(PIKE_FACT), \n                              SVNC_EE = sum(EE_COST)/sum(VOLUME))\n  dataParticipant <- dataParticipant[order(dataParticipant$P_R), ]\n  return(dataParticipant)\n}\n\ngetDPGQuant <- function(pcd, reg) {\n  pcd_reg <- svnc_data[svnc_data$PCODE == pcd & svnc_data$REGION_NAME == reg, \n                       c(\"TDATE\", \"PNAME\", \"TCODE\", \"REGION_NAME\", \"P_NC_UNREG_AVG\")]\n  if (nrow(pcd_reg) == 0)\n    return (\"У данного участника нет ГТП в данном субъекте!\")\n  result <- paste(\"Общее количество ГТП выбранных участников в регионах =\", \n                  as.character(length(unique(pcd_reg$TCODE))))\n  return (result)\n}\n\n# forecasting for single participant\nsingleForecast <- function(pcode, reg_name, nsteps) {\n  # filtering and preparing data\n  last_fact_date <- as.character(cut(max(svnc_data$TDATE), \"month\"))\n  #print(last_fact_date)\n  data <- svnc_data[svnc_data$PCODE == pcode & svnc_data$REGION_NAME == reg_name,\n                    c(\"TDATE\", \"PCODE\", \"PNAME\", \"TCODE\", \"REGION_CODE\", \"REGION_NAME\", \n                      \"P_NC_UNREG_AVG\", \"P_VC_UNREG_AVG\")]\n  data <- filterActuals(data, \"TDATE\", \"TCODE\", last_fact_date)\n  #data$TDATE <- as.Date(data$TDATE)\n  data <- data[, c(\"TDATE\", \"TCODE\", \"PCODE\", \"REGION_NAME\", \n                   \"P_NC_UNREG_AVG\", \"P_VC_UNREG_AVG\")]\n  #print(nrow(data))\n  # calculating history size (with funcion 'rangeByHistorySize' from tsauxfunc package)\n  data_hs <- rangeByHistorySize(data, as.factor(data$TCODE))\n  data_hs_merged <- merge(data, data_hs, \n                            by.x = 'TCODE', by.y = 'FactorLevel', all.x = TRUE, sort = TRUE)\n  data_hs_merged <- data_hs_merged[order(data_hs_merged$TCODE, data_hs_merged$TDATE), ]\n  \n  # separating DPGs with long and short history\n  data_short <- data_hs_merged[data_hs_merged$HistorySize < 24 , ] \n  data_long <- data_hs_merged[data_hs_merged$HistorySize >= 24 , ]\n  # making forecasts\n  if (nrow(data_long) > 0) {\n    fcst_svnc_m_long <- hwforecast_n_step_fwrd(data_long, \"TCODE\", \n                                             \"TDATE\", \"P_NC_UNREG_AVG\", 2, 2)\n    fcst_svnc_ee_long <- hwforecast_n_step_fwrd(data_long, \"TCODE\", \n                                               \"TDATE\", \"P_VC_UNREG_AVG\", 2, 2)\n    \n    df_fcst_long <- data.frame(TCODE = names(fcst_svnc_m_long),\n                               P_NC_UNREG_AVG = as.numeric(fcst_svnc_m_long), \n                               P_VC_UNREG_AVG = as.numeric(fcst_svnc_ee_long))\n  } else {\n    df_fcst_long <- data.frame()\n  }\n  \n  if (nrow(data_short) > 0) {\n    fcst_svnc_m_short <- shortForecast(data_short, \"TCODE\", \n                                     \"TDATE\", \"P_NC_UNREG_AVG\", 2, 2)\n    fcst_svnc_ee_short <- shortForecast(data_short, \"TCODE\", \n                                       \"TDATE\", \"P_VC_UNREG_AVG\", 2, 2)\n    df_fcst_short <- data.frame(TCODE = names(fcst_svnc_m_short), \n                                P_NC_UNREG_AVG = as.numeric(fcst_svnc_m_short),\n                                P_VC_UNREG_AVG = as.numeric(fcst_svnc_ee_short))\n  } else {\n    df_fcst_short <- data.frame()\n  }\n  \n  # merging forecasted values\n  if (nrow(df_fcst_short) > 0 & nrow(df_fcst_long) > 0) {\n    fcst_df <- rbind(df_fcst_long, df_fcst_short)\n  } else if (nrow(df_fcst_short) > 0 & nrow(df_fcst_long) == 0) {\n    fcst_df <- df_fcst_short\n  } else {\n    fcst_df <- df_fcst_long\n  }\n  supp_data <- data[data$TDATE == max(data$TDATE), \n                      c('TCODE', 'PCODE', 'REGION_NAME')]\n  dpg_fcst <- merge(fcst_df, supp_data, \n                  by = 'TCODE', all.x = TRUE, sort = TRUE)[, \n                  c('PCODE', 'REGION_NAME', 'TCODE', 'P_NC_UNREG_AVG', 'P_VC_UNREG_AVG')]\n  res <- summarize(group_by(dpg_fcst, PCODE, REGION_NAME), \n                   SVNC_M_FCST = mean(P_NC_UNREG_AVG), \n                   SVNC_EE_FCST = mean(P_VC_UNREG_AVG))\n\n  names(res) <- c(\"Код участника\", \"Регион\", \"Проноз СВНЦ на мощность\", \"Прогноз СВНЦ на ЭЭ\")\n  return (res)\n}\n\n# forecating for all participants\nforecastForEach <- function(updateProgress = NULL) {\n  forecasts <- data.frame(PCODE = character(), REGION = character(), \n                          SVNC_M_FCST = numeric(), SVNC_EE_FCST = numeric(), \n                          stringsAsFactors = FALSE)\n  pcodes_regions <- unique(svnc_data[svnc_data$TDATE == max(svnc_data$TDATE), \n                           c(\"PCODE\", \"REGION_NAME\")])\n  for (i in seq(1:nrow(pcodes_regions))) {\n    one_row <- pcodes_regions[i, ]\n    if (is.function(updateProgress)) {\n      pr_value <- i / nrow(pcodes_regions)\n      text <- paste0(\"Forecasting prices for \", one_row$PCODE, \" - \"\n                     , one_row$REGION_NAME)\n      updateProgress(value = pr_value, detail = text)\n    }\n    res <- singleForecast(one_row$PCODE, one_row$REGION_NAME)\n    # if res is in the list of actual GP-REGION pairs then add to accum. data\n    if (nrow(merge(res, gp_region[, c('PCODE', 'REGION_CODE')])) > 0) {\n      forecasts[i, ] <- res\n      forecasts_to_save[i, ] <- res\n    }\n  }\n  names(forecasts) <- c(\"Код участника\", \"Регион\", \"Проноз СВНЦ на мощность\", \"Прогноз СВНЦ на ЭЭ\")\n  return(forecasts)\n}\n\nshinyServer(\n  function(input, output) {\n\n    output$regions <- renderUI({\n      selectInput(inputId = \"regions\", label = \"Выберите субъект федерации\", \n                              choices = getRegions(input$pcode), multiple = TRUE)\n\n    })\n    \n    output$regions_forecast <- renderUI({\n      selectInput(inputId = \"regions_forecast\", label = \"Выберите субъект федерации\", \n                  choices = getRegions(input$pcd_forecast))\n    })\n    \n    output$fact_svnc <- renderPlot({ \n      d <- getFactParticipant(input$pcode, input$regions)\n      if (input$grapIndicator == \"СВНЦ на мощность\") {\n        ggplot(d, aes(x = TDATE, y = SVNC_M, colour = P_R)) +\n          geom_line() + xlab(\"\") + ylab(\"СВНЦ на мощность, руб./МВт\") +\n          theme(text = element_text(size = 18), legend.position = 'bottom') \n      } else {\n        ggplot(d, aes(x = TDATE, y = SVNC_EE, colour = P_R)) +\n          geom_line() + xlab(\"\") + ylab(\"СВНЦ на электроэнергию, руб./МВт*ч\") +\n          theme(text = element_text(size = 18), legend.position = 'bottom') \n      }\n    })\n    \n    # function, that forms fact data\n    getFactTable <- function() {\n      d <- getFactParticipant(input$pcode, input$regions)\n      d$TDATE <- format(d$TDATE,'%Y-%m-%d')\n      names(d) <- c(\"Дата\", \"Наименование участника\", \"Код участника - Регион\", \"СВНЦ на мощность, руб./МВт\", \"СВНЦ на электроэнергию, руб./МВт*ч\")\n      d\n    }\n    \n    # output of the fact data to the table\n    output$svnc_table <- renderTable({\n      getFactTable()\n    })\n    \n    output$downloadFactData <- downloadHandler(\n      filename = 'fact_svnc.xlsx',\n      content = function(file) {\n        data <- as.data.frame(getFactTable())\n        write.xlsx(data, file)\n      }\n    )\n    \n    forecastTable <- eventReactive(input$launchForecast, {\n      if (input$all == FALSE) {\n        singleForecast(input$pcd_forecast, input$regions_forecast)\n      } else {\n        # Creating a progress object\n        progress <- shiny::Progress$new(style = 'notification')\n        progress$set(message = \"Forecasting, please, wait ...\", value = 0)\n        # Close the progress when this reactive exits (even if there's an error)\n        on.exit(progress$close())\n        \n        # Create a closure to update progress.\n        # Each time this is called:\n        # - If `value` is NULL, it will move the progress bar 1/5 of the remaining\n        #   distance. If non-NULL, it will set the progress to that value.\n        # - It also accepts optional detail text.\n        updateProgress <- function(value = NULL, detail = NULL) {\n          if (is.null(value)) {\n            value <- progress$getValue()\n            value <- value + (progress$getMax() - value) / 5\n          }\n          progress$set(value = value, detail = detail)\n        }\n        \n        # launch forecasting\n        forecastForEach(updateProgress)\n      }\n\n    })\n    \n    # output of the forecasted data for each pair PCODE-REGION\n    output$svnc_n_fcst <- renderTable({\n      x <- forecastTable()\n      save(x, file = \"forecasts.RData\")\n      x\n    })\n    \n    output$downloadForecastData <- downloadHandler(\n      filename = 'forecast_svnc.xlsx',\n      content = function(file) {\n        load(\"shiny_app/data_sources/forecasts.RData\")\n        x <- as.data.frame(x)\n        names(x) <- c(\"PCODE\", \"REGION_NAME\", \"PRICE_N\", \"PRICE_EE\")\n        x <- merge(x, unique(dpg_gp_info[, c(\"PCODE\", \"REGION_NAME\", \"REGION_CODE\")]), \n                   by = c(\"PCODE\", \"REGION_NAME\"), all.x = TRUE)\n        x <- na.omit(x)\n        #### Formating for output ####\n        dpg_gp_info$dpg_count <- 1\n        # selecting only PCODES with one dpg in region\n        single_dpg <- dpg_gp_info %>%\n          group_by(PCODE, REGION_CODE) %>%\n          summarize(total_dpg_count = sum(dpg_count)) %>%\n          filter(total_dpg_count == 1) %>%\n          select(PCODE, REGION_CODE)\n        # selecting only PCODES with more than one dpg in region\n        multiple_dpgs <- dpg_gp_info %>%\n          group_by(PCODE, PNAME, REGION_CODE, REGION_NAME) %>%\n          summarize(total_dpg_count = sum(dpg_count)) %>%\n          filter(total_dpg_count != 1) %>%\n          select(PCODE, PNAME, REGION_CODE, REGION_NAME)\n        \n        single_dpg <- merge(dpg_gp_info, single_dpg, \n                            by = c('PCODE', 'REGION_CODE'), all.y = TRUE) %>%\n          select(PCODE, PNAME, REGION_CODE, REGION_NAME, TCODE)\n        \n        # merging output data\n        output <- merge(x, single_dpg, \n                        by = c('PCODE', 'REGION_CODE'), all.x = TRUE, sort = FALSE) %>%\n          merge(multiple_dpgs, by = c('PCODE', 'REGION_CODE'), all.x = TRUE, sort = TRUE)\n        output$PNAME <- ifelse(!is.na(output$PNAME.x), output$PNAME.x, output$PNAME.y) \n        output$REGION_NAME <- ifelse(!is.na(output$REGION_NAME.x), output$REGION_NAME.x, \n                                     output$REGION_NAME.y)\n        output$REGION_CODE <- as.numeric(output$REGION_CODE)\n        output <- output[order(output$PCODE, output$REGION_CODE), \n                         c('PNAME', 'TCODE', 'REGION_CODE', \n                           'REGION_NAME', 'PCODE', 'PRICE_EE', 'PRICE_N')]\n        \n        print(dim(output))\n        write.xlsx(output, file)\n      }\n    ) \n    \n    \n  }\n)",
    "created" : 1485772027236.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "10|42|15|0|\n19|60|26|0|\n29|41|43|0|\n65|52|76|0|\n80|62|85|0|\n89|58|94|0|\n98|79|124|0|\n128|70|148|0|\n156|38|159|0|\n162|27|170|0|\n172|32|176|0|\n194|35|202|0|\n",
    "hash" : "4096415154",
    "id" : "8C67EFD1",
    "lastKnownWriteTime" : 1489585010,
    "path" : "C:/!zemskov/svnc_forecast/shiny_app/server.R",
    "project_path" : "shiny_app/server.R",
    "properties" : {
    },
    "relative_order" : 8,
    "source_on_save" : false,
    "type" : "r_source"
}