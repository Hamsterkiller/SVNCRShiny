with TRADE_SESSIONS as
(select
trade_session_id
from
ODS_002.trade_session
where
target_date between to_date('",begin_date,"','yyyy-mm-dd')
and to_date('",end_date,"','yyyy-mm-dd')
and valid_to_dttm > sysdate()
)
select
trunc(ts.target_date, 'month')  as TDATE
,t.trader_code as TCODE
,nvl(sum(d.volume)/1000, 0) as VOLUME
from
ODS_002.trade_session ts,
ODS_002.wh_deal_data_hour d,
ODS_002.wh_trader t
where
ts.trade_session_id = d.trade_session_id
and ts.trade_session_id = t.trade_session_id
and d.dpg_code = t.trader_code
and d.deal_type = 3
and d.direction = 1
and d.volume > 0
and (nvl(t.fed_station::NUMERIC,0) = 0
or t.is_guarantee_supply_co = 1)
and ts.target_date between to_date('",begin_date,"','yyyy-mm-dd')
and to_date('",end_date,"','yyyy-mm-dd')
and nvl(t.is_fsk::NUMERIC,0) = 0
and nvl(t.is_unpriced_zone::NUMERIC,0) = 0
and nvl(t.region_code::NUMERIC, 0) > 0
and nvl(t.oes::NUMERIC,0) > 0
and ts.valid_to_dttm > sysdate()
and d.valid_to_dttm > sysdate()
and t.valid_to_dttm > sysdate()
and ts.trade_session_id in (select * from TRADE_SESSIONS)
and d.trade_session_id in (select * from TRADE_SESSIONS)
and t.trade_session_id in (select * from TRADE_SESSIONS)
group by
t.price_zone_code
,t.trader_code
,t.region_code
,t.is_guarantee_supply_co
,trunc(ts.target_date , 'month')
order by
tcode
,region_code
,tdate")
cursor <- dbGetQuery(connection, query)
message("query was executed successfuly")
return (cursor)
}
retrieved_volumes_new <- extractVolumesFact(verticaConnection, begin_date, end_date)
retrieved_volumes_new$TDATE <- as.Date(retrieved_volumes_new$TDATE)
retrieved_volumes <- rbind(retrieved_volumes, retrieved_volumes_new)
retrieved_volumes <- retrieved_volumes[order(retrieved_volumes$TCODE, retrieved_volumes$TDATE), ]
save(retrieved_volumes, file = "VOLUMES_FACT.RData")
svnc_pikes_volumes <- merge(svnc_with_pikes, retrieved_volumes_new,
by = c("TDATE", "TCODE"), all.x = TRUE, sort = TRUE)
rm(svnc_with_pikes)
View(svnc_pikes_volumes)
extractKOMPricesPZ <- function(connection, begin_year, end_year, ...) {
message("extracting KOM prices ...")
message("starting query ...")
message("from ", begin_year, " to ", end_year)
query <-
paste("
select
target_date as TDATE,
price_zone_code as PZ,
price_kom
from
mform.result_com_price_zone
where
target_date between to_date('",begin_year,"','yyyy-mm-dd')
and to_date('",end_year,"','yyyy-mm-dd')
and end_ver = 999999999999999
")
cursor <- dbGetQuery(connection, query)
message("query was executed successfuly")
return (cursor)
}
retrieved_KOM_PZ <- extractKOMPricesPZ(jdbcConnectionMFORM, begin_year, end_year)
retrieved_KOM_PZ$TDATE <- as.Date(retrieved_KOM_PZ$TDATE)
retrieved_KOM_PZ$YEAR <- format(retrieved_KOM_PZ$TDATE, "%Y")
retrieved_KOM_PZ <- retrieved_KOM_PZ[, -1]
save(retrieved_KOM_PZ, file = "KOM_PZ_PRICES.RData")
extractKOMPricesZSP <- function(connection, begin_date, end_date, ...) {
message("starting query ...")
message("from ", begin_date, " to ", end_date)
query <-
paste("
select
zsp_code,
target_date as tdate,
price_kom as zsp_price_kom
from
mform.kom_result_zsp_dfr
where
end_ver = 999999999999999
and target_date between to_date('",begin_date,"', 'yyyy-mm-dd') and
to_date('",end_date,"', 'yyyy-mm-dd')
order by
zsp_code, tdate
")
cursor <- dbGetQuery(connection, query)
message("query was executed successfuly")
return (cursor)
}
retrieved_KOM_ZSP <- extractKOMPricesZSP(jdbcConnectionMFORM, history_begin_date, forecast_date)
retrieved_KOM_ZSP$TDATE <- as.Date(retrieved_KOM_ZSP$TDATE)
retrieved_KOM_ZSP$YEAR <- format(retrieved_KOM_ZSP$TDATE, "%Y")
retrieved_KOM_ZSP <- retrieved_KOM_ZSP[, -2]
svnc_pikes_volumes$YEAR <- format(svnc_pikes_volumes$TDATE, "%Y")
svnc_p_v_kom_new <- merge(svnc_pikes_volumes, retrieved_KOM_PZ,
by = c("YEAR", "PZ"), all.x = TRUE, sort = FALSE)
svnc_p_v_kom_new <- merge(svnc_p_v_kom_new, retrieved_KOM_ZSP, by = c("YEAR", "ZSP_CODE"),
all.x = TRUE, sort = FALSE)
svnc_p_v_kom_new$KOM_PRICE <- ifelse(is.na(svnc_p_v_kom_new$PRICE_KOM), svnc_p_v_kom_new$ZSP_PRICE_KOM,
svnc_p_v_kom_new$PRICE_KOM)
svnc_p_v_kom_new <- svnc_p_v_kom_new[, -c(14, 15)]
svnc_p_v_kom <- rbind(svnc_p_v_kom, svnc_p_v_kom_new)
svnc_p_v_kom <- svnc_p_v_kom[order(svnc_p_v_kom$TDATE, svnc_p_v_kom$TCODE), ]
save(svnc_p_v_kom, file = "C:/!zemskov/svnc_forecast/data_sources/SVNC_P_V_KOM_FACT.RData")
View(svnc_p_v_kom)
rm(list = ls())
library(tsauxfunc)
setwd("C:/!zemskov/svnc_forecast/data_sources")
# SVNC
load("SVNC_P_V_KOM_FACT.RData")
# Pikes
load("PIKES_FACT.RData")
# Volumes
load("VOLUMES_FACT.RData")
# KOM Prices
load("KOM_PZ_PRICES.RData")
# DPG-info
load("DPG_GP_INFO.RData")
forecasting_month <- as.Date(cut(as.Date(Sys.Date()) + 15, "month"))
last_fact_date <- as.character(cut(forecasting_month - 61, "month"))
forecasting_month
last_fact_date
last_fact_date <- as.character(cut(forecasting_month - 31, "month"))
last_fact_date
svnc_src <- svnc_p_v_kom
rm(svnc_p_v_kom)
#svnc_src$date <- as.Date(svnc_src$TDATE)
data <- svnc_src
svnc_src <- svnc_src[, c('TDATE', 'TCODE', 'P_NC_UNREG_AVG', 'P_VC_UNREG_AVG',
'VOLUME', 'PIKE_FACT')]
svnc_src <- filterActuals(svnc_src, "TDATE", "TCODE", last_fact_date)
svnc_src$TCODE <- as.factor(svnc_src$TCODE)
svnc_hs <- rangeByHistorySize(svnc_src, as.factor(svnc_src$TCODE))
svnc_hs_merged <- merge(svnc_src, svnc_hs,
by.x = 'TCODE', by.y = 'FactorLevel', all.x = TRUE, sort = TRUE)
svnc_hs_merged <- svnc_hs_merged[order(svnc_hs_merged$TCODE, svnc_hs_merged$TDATE), ]
rm(svnc_hs)
svnc_short <- svnc_hs_merged[svnc_hs_merged$HistorySize < 24 , ]
svnc_long <- svnc_hs_merged[svnc_hs_merged$HistorySize >= 24 , ]
pikes <- pikes[pikes$TDATE < forecasting_month, ]
SVNC_DPG_list <- unique(svnc_hs_merged[svnc_hs_merged$TDATE > forecasting_month - 65, ]$TCODE)
rm(svnc_hs_merged)
pikes <- pikes[which(pikes$TCODE %in% SVNC_DPG_list), ]
pikes_hs <- rangeByHistorySize(pikes, as.factor(pikes$TCODE))
pikes_hs_merged <- merge(pikes, pikes_hs,
by.x = 'TCODE', by.y = 'FactorLevel', all.x = TRUE, sort = TRUE)
pikes_hs_merged <- pikes_hs_merged[order(pikes_hs_merged$TCODE, pikes_hs_merged$TDATE), ]
rm(pikes_hs)
pikes_short <- pikes_hs_merged[pikes_hs_merged$HistorySize < 24 , ]
pikes_long <- pikes_hs_merged[pikes_hs_merged$HistorySize >= 24 , ]
retrieved_volumes <- retrieved_volumes[retrieved_volumes$TDATE < forecasting_month, ]
retrieved_volumes <- retrieved_volumes[which(retrieved_volumes$TCODE %in% SVNC_DPG_list), ]
retrieved_volumes$TDATE <- as.Date(retrieved_volumes$TDATE)
# ranging by history
volumes_hs <- rangeByHistorySize(retrieved_volumes, as.factor(retrieved_volumes$TCODE))
volumes_hs_merged <- merge(retrieved_volumes, volumes_hs,
by.x = 'TCODE', by.y = 'FactorLevel', all.x = TRUE, sort = TRUE)
volumes_hs_merged <- volumes_hs_merged[order(volumes_hs_merged$TCODE,
volumes_hs_merged$TDATE), ]
rm(volumes_hs)
volumes_short <- volumes_hs_merged[volumes_hs_merged$HistorySize < 24 , ]
volumes_long <- volumes_hs_merged[volumes_hs_merged$HistorySize >= 24 , ]
fcst_pike_long <- hwforecast_n_step_fwrd(pikes_long, "TCODE",
"TDATE", "PIKE_FACT", 1, 1)
fcst_volumes_long <- hwforecast_n_step_fwrd(volumes_long, "TCODE",
"TDATE", "VOLUME", 1, 1)
fcst_pike_short <- shortForecast(pikes_short, "TCODE",
"TDATE", "PIKE_FACT", 1, 1)
fcst_volumes_short <- shortForecast(volumes_short, "TCODE",
"TDATE", "VOLUME", 1, 1)
View(svnc_src)
fcst_svnc_m_long <- hwforecast_n_step_fwrd(svnc_long, "TCODE",
"TDATE", "P_NC_UNREG_AVG", 2, 2)
fcst_svnc_ee_long <- hwforecast_n_step_fwrd(svnc_long, "TCODE",
"TDATE", "P_VC_UNREG_AVG", 2, 2)
fcst_svnc_m_short <- shortForecast(svnc_short, "TCODE",
"TDATE", "P_NC_UNREG_AVG", 2, 2)
fcst_svnc_ee_short <- shortForecast(svnc_short, "TCODE",
"TDATE", "P_VC_UNREG_AVG", 2, 2)
tcodes_long <- data.frame(TCODE = names(fcst_svnc_m_long),
P_NC_UNREG_AVG = as.numeric(fcst_svnc_m_long),
P_VC_UNREG_AVG = as.numeric(fcst_svnc_ee_long))
tcodes_short <- data.frame(TCODE = names(fcst_svnc_m_short),
P_NC_UNREG_AVG = as.numeric(fcst_svnc_m_short),
P_VC_UNREG_AVG = as.numeric(fcst_svnc_ee_short))
tcodes <- rbind(tcodes_long, tcodes_short)
tpcodesregs <- data[data$TDATE == as.Date('2016-06-01'),
c('TCODE', 'PCODE', 'REGION_CODE')]
result_SVNC <- merge(tpcodesregs, tcodes,
by = 'TCODE', all.x = TRUE, sort = TRUE)[, c('TCODE', 'PCODE', 'REGION_CODE',
'P_NC_UNREG_AVG', 'P_VC_UNREG_AVG')]
# joining pikes and volumes
pikes_long <- data.frame(TCODE = names(fcst_pike_long),
PIKE = as.numeric(fcst_pike_long))
pikes_short <- data.frame(TCODE = names(fcst_pike_short),
PIKE = as.numeric(fcst_pike_short))
pikes_forecast <- rbind(pikes_long, pikes_short)
#VOLUMES
volumes_long <- data.frame(TCODE = names(fcst_volumes_long),
VOLUME = as.numeric(fcst_volumes_long))
volumes_short <- data.frame(TCODE = names(fcst_volumes_short),
VOLUME = as.numeric(fcst_volumes_short))
volumes_forecast <- rbind(volumes_long, volumes_short)
# merging all together
result <- merge(result_SVNC, pikes_forecast, by = 'TCODE', all.x = TRUE, sort = TRUE)
result <- merge(result, volumes_forecast, by = 'TCODE', all.x = TRUE, sort = TRUE)
result <- result[result$TCODE %in% dpg_gp_info$TCODE, ]
# calculating costs of N and EE
result$N_COST <- result$P_NC_UNREG_AVG * result$PIKE
result$EE_COST <- result$P_VC_UNREG_AVG * result$VOLUME
library(dplyr)
result_grouped <- summarize(group_by(result, PCODE, REGION_CODE),
PRICE_N = sum(N_COST)/sum(PIKE),
PRICE_EE = sum(EE_COST)/sum(VOLUME))
result_grouped <- result_grouped[with(result_grouped, order(PCODE, REGION_CODE)), ]
library(xlsx)
write.xlsx(as.data.frame(result_grouped), file = 'svnc_m_ee_mar2017_fcst_weighted_avg.xlsx', sheetName = 'SVNC_M_ee')
dpg_gp_info$dpg_count <- 1
# selecting only PCODES with one dpg in region
single_dpg <- dpg_gp_info %>%
group_by(PCODE, REGION_CODE) %>%
summarize(total_dpg_count = sum(dpg_count)) %>%
filter(total_dpg_count == 1) %>%
select(PCODE, REGION_CODE)
# selecting only PCODES with more than one dpg in region
multiple_dpgs <- dpg_gp_info %>%
group_by(PCODE, PNAME, REGION_CODE, REGION_NAME) %>%
summarize(total_dpg_count = sum(dpg_count)) %>%
filter(total_dpg_count != 1) %>%
select(PCODE, PNAME, REGION_CODE, REGION_NAME)
single_dpg <- merge(dpg_gp_info, single_dpg,
by = c('PCODE', 'REGION_CODE'), all.y = TRUE) %>%
select(PCODE, PNAME, REGION_CODE, REGION_NAME, TCODE)
# merging output data
output <- merge(result_grouped, single_dpg,
by = c('PCODE', 'REGION_CODE'), all.x = TRUE, sort = FALSE) %>%
merge(multiple_dpgs, by = c('PCODE', 'REGION_CODE'), all.x = TRUE, sort = TRUE)
output$PNAME <- ifelse(!is.na(output$PNAME.x), output$PNAME.x, output$PNAME.y)
output$REGION_NAME <- ifelse(!is.na(output$REGION_NAME.x), output$REGION_NAME.x,
output$REGION_NAME.y)
output$REGION_CODE <- as.numeric(output$REGION_CODE)
output <- output[order(output$PCODE, output$REGION_CODE),
c('PNAME', 'TCODE', 'REGION_CODE',
'REGION_NAME', 'PCODE', 'PRICE_EE', 'PRICE_N')]
write.xlsx(output, file = "FORMATTED_OUTPUT.xlsx",
sheetName = "svnc_forecast", row.names = FALSE)
shiny::runApp('C:/!zemskov/svnc_forecast/shiny_app')
shiny::runApp('C:/!zemskov/svnc_forecast/shiny_app')
# clearing workspace
rm(list = ls())
# loading fact data
load("SVNC_P_V_KOM_FACT.RData")
fact_data <- svnc_p_v_kom
comp_month <- "2017-01-01"
fact_data <- fact_data[fact_data$TDATE == as.Date(comp_month), ]
fact_data$N_COST <- fact_data$P_NC_UNREG_AVG * fact_data$PIKE_FACT
fact_data$EE_COST <- fact_data$P_VC_UNREG_AVG * fact_data$VOLUME
fact_data_filtered <- fact_data[, c("TDATE", "PCODE", "REGION_CODE", "N_COST",
"EE_COST", "PIKE_FACT", "VOLUME")]
library(dplyr)
fact_data_grouped <- summarize(group_by(fact_data_filtered, TDATE, PCODE,  REGION_CODE),
SVNC_M_FACT = sum(N_COST)/sum(PIKE_FACT),
SVNC_EE_FACT = sum(EE_COST)/sum(VOLUME))
fact_data_grouped <- fact_data_grouped[, c("PCODE", "REGION_CODE", "SVNC_M_FACT", "SVNC_EE_FACT")]
fact_data_grouped$REGION_CODE <- as.numeric(fact_data_grouped$REGION_CODE)
fact_data_grouped$PCODE <- as.character(trimws(fact_data_grouped$PCODE, which = "both"))
# loading forecasts
library(xlsx)
fcst_data <- read.xlsx(file = "C:/!zemskov/svnc_forecast/data_sources/svnc_m_ee_dec2016_fcst_weighted_avg.xlsx",
sheetName = "SVNC_M_ee")
fcst_data <- read.xlsx(file = "C:/!zemskov/svnc_forecast/data_sources/svnc_m_ee_jan2016_fcst_weighted_avg.xlsx",
sheetName = "SVNC_M_ee")
fcst_data$PCODE <- as.character(trimws(fcst_data$PCODE, which = "both"))
fcst_data$REGION_CODE <- as.numeric(as.character(fcst_data$REGION_CODE))
library(xlsx)
fcst_data <- read.xlsx(file = "C:/!zemskov/svnc_forecast/data_sources/svnc_m_ee_jan2016_fcst_weighted_avg.xlsx",
sheetName = "SVNC_M_ee")
fcst_data$PCODE <- as.character(trimws(fcst_data$PCODE, which = "both"))
fcst_data <- read.xlsx(file = "C:/!zemskov/svnc_forecast/data_sources/svnc_m_ee_jan2017_fcst_weighted_avg.xlsx",
sheetName = "SVNC_M_ee")
fcst_data$PCODE <- as.character(trimws(fcst_data$PCODE, which = "both"))
fcst_data$REGION_CODE <- as.numeric(as.character(fcst_data$REGION_CODE))
plan_fact <- merge(fcst_data, fact_data_grouped,
by = c('PCODE', 'REGION_CODE'), all.x = TRUE, sort = TRUE)
quality <- na.omit(plan_fact)
quality$error_M <- quality$PRICE_N - quality$SVNC_M_FACT
quality$abs_error_M <- abs(quality$PRICE_N - quality$SVNC_M_FACT)
quality$pcnt_error_M <- quality$abs_error_M / quality$SVNC_M_FACT * 100
quality$MAE_M <- mean(quality$abs_error_M)
quality$MAE_pcnt_M <- mean(quality$pcnt_error_M)
quality$median_error_M <- median(quality$abs_error_M)
quality$pcnt_median_error_M <- median(quality$pcnt_error_M)
quality$error_EE <- quality$PRICE_EE - quality$SVNC_EE_FACT
quality$abs_error_EE <- abs(quality$PRICE_EE - quality$SVNC_EE_FACT)
quality$pcnt_error_EE <- quality$abs_error_EE / quality$SVNC_EE_FACT * 100
quality$MAE_EE <- mean(quality$abs_error_EE)
quality$MAE_pcnt_EE <- mean(quality$pcnt_error_EE)
quality$median_error_EE <- median(quality$abs_error_EE)
quality$pcnt_median_error_EE <- median(quality$pcnt_error_EE)
write.xlsx(quality, "january_2017_quality_report(weighted).xlsx")
View(quality)
shiny::runApp('C:/!zemskov/svnc_forecast/shiny_app')
fcst_data <- read.xlsx(file = "C:/!zemskov/svnc_forecast/data_sources/svnc_m_ee_jan2017_fcst(hw-arima-assembly).xlsx",
sheetName = "SVNC_M_ee")
fcst_data$PCODE <- as.character(trimws(fcst_data$PCODE, which = "both"))
fcst_data$REGION_CODE <- as.numeric(as.character(fcst_data$REGION_CODE))
#fcst_data <- fcst_data[, c("PCODE", "REGION_CODE", "PRICE")]
plan_fact <- merge(fcst_data, fact_data_grouped,
by = c('PCODE', 'REGION_CODE'), all.x = TRUE, sort = TRUE)
quality <- na.omit(plan_fact)
quality$error_M <- quality$PRICE_N - quality$SVNC_M_FACT
quality$abs_error_M <- abs(quality$PRICE_N - quality$SVNC_M_FACT)
quality$pcnt_error_M <- quality$abs_error_M / quality$SVNC_M_FACT * 100
quality$MAE_M <- mean(quality$abs_error_M)
quality$MAE_pcnt_M <- mean(quality$pcnt_error_M)
quality$median_error_M <- median(quality$abs_error_M)
quality$pcnt_median_error_M <- median(quality$pcnt_error_M)
quality$error_EE <- quality$PRICE_EE - quality$SVNC_EE_FACT
quality$abs_error_EE <- abs(quality$PRICE_EE - quality$SVNC_EE_FACT)
quality$pcnt_error_EE <- quality$abs_error_EE / quality$SVNC_EE_FACT * 100
quality$MAE_EE <- mean(quality$abs_error_EE)
quality$MAE_pcnt_EE <- mean(quality$pcnt_error_EE)
quality$median_error_EE <- median(quality$abs_error_EE)
quality$pcnt_median_error_EE <- median(quality$pcnt_error_EE)
fcst_data <- read.xlsx(file = "C:/!zemskov/svnc_forecast/data_sources/svnc_m_ee_jan2017_fcst(hw-arima-assembly).xlsx",
sheetName = "SVNC_M_ee")
fcst_data$PCODE <- as.character(trimws(fcst_data$PCODE, which = "both"))
fcst_data$REGION_CODE <- as.numeric(as.character(fcst_data$REGION_CODE))
View(fcst_data)
View(quality)
regions <- read.csv('C:/!zemskov/svnc_forecast/data_sources/REGION_NAME.csv',sep = ';')
View(regions)
fcst_data <- merge(fcst_data, regions[, 'REGION_CODE', 'REGION_NAME'],
by = c('REGION_NAME'), all.x = TRUE)
names(fcst_data)
str(fcst_data)
fcst_data <- read.xlsx(file = "C:/!zemskov/svnc_forecast/data_sources/svnc_m_ee_jan2017_fcst(hw-arima-assembly).xlsx",
sheetName = "SVNC_M_ee")
Viw(fcst_data)
View(fcst_data)
fcst_data <- read.xlsx(file = "C:/!zemskov/svnc_forecast/data_sources/svnc_m_ee_jan2017_fcst(hw-arima-assembly).xlsx",
sheetName = "SVNC_M_ee", encoding = 'windows-1251')
View(fcst_data)
fcst_data <- read.xlsx(file = "C:/!zemskov/svnc_forecast/data_sources/svnc_m_ee_jan2017_fcst(hw-arima-assembly).xlsx",
sheetName = "SVNC_M_ee", encoding = 'cp1251')
View(fcst_data)
fcst_data <- read.xlsx(file = "C:/!zemskov/svnc_forecast/data_sources/svnc_m_ee_jan2017_fcst(hw-arima-assembly).xlsx",
sheetName = "SVNC_M_ee", encoding = 'UTF-8')
View(fcst_data)
names9fcst_data
names(fcst_data)
names(fcst_data) <- c('id', 'PCODE', 'REGION_NAME', 'PRICE_N', 'PRICE_EE')
fcst_data$PCODE <- as.character(trimws(fcst_data$PCODE, which = "both"))
fcst_data$REGION_NAME <- as.character(trimws(fcst_data$REGION_NAME, which = "both"))
head(fcst_data)
fcst_data <- merge(fcst_data, regions[, 'REGION_CODE', 'REGION_NAME'],
by = c('REGION_NAME'), all.x = TRUE)
names(regions)
fcst_data <- merge(fcst_data, regions[, 'REGION_CODE', 'REGION_NAME'],
by.x = c('REGION_NAME'), by.y = c('REG_NAME'), all.x = TRUE)
str(fcst_data)
str(regions)
regions <- read.csv('C:/!zemskov/svnc_forecast/data_sources/REGION_NAME.csv'
,sep = ';', stringsAsFactors = FALSE)
fcst_data <- merge(fcst_data, regions[, 'REGION_CODE', 'REGION_NAME'],
by.x = c('REGION_NAME'), by.y = c('REG_NAME'), all.x = TRUE)
str(fcst_data)
str(regions)
fcst_data <- merge(fcst_data, regions[, 'REG', 'REG_NAME'],
by.x = c('REGION_NAME'), by.y = c('REG_NAME'), all.x = TRUE)
fcst_data <- merge(fcst_data, regions[, c('REG', 'REG_NAME')],
by.x = c('REGION_NAME'), by.y = c('REG_NAME'), all.x = TRUE)
nrow(fcst_data)
View(fcst_data\)
View(fcst_data)
fcst_data <- select(fcst_data, PCODE, REG, REGION_NAME, PRICE_EE, PRICE_N)
View(fcst_data)
names(fcst_data) <- c('PCODE', 'REGION_CODE', 'REGION_NAME', 'PRICE_EE', 'PRICE_N')
str(fcst_data)
plan_fact <- merge(fcst_data, fact_data_grouped,
by = c('PCODE', 'REGION_CODE'), all.x = TRUE, sort = TRUE)
quality <- na.omit(plan_fact)
quality$error_M <- quality$PRICE_N - quality$SVNC_M_FACT
quality$abs_error_M <- abs(quality$PRICE_N - quality$SVNC_M_FACT)
quality$pcnt_error_M <- quality$abs_error_M / quality$SVNC_M_FACT * 100
quality$MAE_M <- mean(quality$abs_error_M)
quality$MAE_pcnt_M <- mean(quality$pcnt_error_M)
quality$median_error_M <- median(quality$abs_error_M)
quality$pcnt_median_error_M <- median(quality$pcnt_error_M)
quality$error_EE <- quality$PRICE_EE - quality$SVNC_EE_FACT
quality$abs_error_EE <- abs(quality$PRICE_EE - quality$SVNC_EE_FACT)
quality$pcnt_error_EE <- quality$abs_error_EE / quality$SVNC_EE_FACT * 100
quality$MAE_EE <- mean(quality$abs_error_EE)
quality$MAE_pcnt_EE <- mean(quality$pcnt_error_EE)
quality$median_error_EE <- median(quality$abs_error_EE)
quality$pcnt_median_error_EE <- median(quality$pcnt_error_EE)
fact_data_grouped <- summarize(group_by(fact_data_filtered, TDATE, PCODE,  REGION_CODE),
SVNC_M_FACT = sum(N_COST)/sum(PIKE_FACT),
SVNC_EE_FACT = sum(EE_COST)/sum(VOLUME))
fact_data_grouped <- fact_data_grouped[, c("PCODE", "REGION_CODE", "SVNC_M_FACT", "SVNC_EE_FACT")]
fact_data_grouped$REGION_CODE <- as.numeric(fact_data_grouped$REGION_CODE)
fact_data_grouped$PCODE <- as.character(trimws(fact_data_grouped$PCODE, which = "both"))
# clearing workspace
rm(list = ls())
# loading fact data
load("SVNC_P_V_KOM_FACT.RData")
regions <- read.csv('C:/!zemskov/svnc_forecast/data_sources/REGION_NAME.csv'
,sep = ';', stringsAsFactors = FALSE)
fact_data <- svnc_p_v_kom
#rm(svnc_p_v_kom)
comp_month <- "2017-01-01"
#fact_data$TDATE <- as.Date(fact_data$TDATE)
fact_data <- fact_data[fact_data$TDATE == as.Date(comp_month), ]
#fact_data_filtered <- fact_data[fact_data$TDATE == as.Date(comp_month),
#      c("TDATE", "PCODE", "TCODE", "REGION_CODE", "P_VC_UNREG_AVG", "P_NC_UNREG_AVG")]
fact_data$N_COST <- fact_data$P_NC_UNREG_AVG * fact_data$PIKE_FACT
fact_data$EE_COST <- fact_data$P_VC_UNREG_AVG * fact_data$VOLUME
fact_data_filtered <- fact_data[, c("TDATE", "PCODE", "REGION_CODE", "N_COST",
"EE_COST", "PIKE_FACT", "VOLUME")]
library(dplyr)
fact_data_grouped <- summarize(group_by(fact_data_filtered, TDATE, PCODE,  REGION_CODE),
SVNC_M_FACT = sum(N_COST)/sum(PIKE_FACT),
SVNC_EE_FACT = sum(EE_COST)/sum(VOLUME))
fact_data_grouped <- fact_data_grouped[, c("PCODE", "REGION_CODE", "SVNC_M_FACT", "SVNC_EE_FACT")]
fact_data_grouped$REGION_CODE <- as.numeric(fact_data_grouped$REGION_CODE)
fact_data_grouped$PCODE <- as.character(trimws(fact_data_grouped$PCODE, which = "both"))
library(xlsx)
fcst_data <- read.xlsx(file = "C:/!zemskov/svnc_forecast/data_sources/svnc_m_ee_jan2017_fcst(hw-arima-assembly).xlsx",
sheetName = "SVNC_M_ee", encoding = 'UTF-8')
names(fcst_data) <- c('id', 'PCODE', 'REGION_NAME', 'PRICE_N', 'PRICE_EE')
fcst_data$PCODE <- as.character(trimws(fcst_data$PCODE, which = "both"))
fcst_data$REGION_NAME <- as.character(trimws(fcst_data$REGION_NAME, which = "both"))
fcst_data <- merge(fcst_data, regions[, c('REG', 'REG_NAME')],
by.x = c('REGION_NAME'), by.y = c('REG_NAME'), all.x = TRUE)
fcst_data <- select(fcst_data, PCODE, REG, REGION_NAME, PRICE_EE, PRICE_N)
names(fcst_data) <- c('PCODE', 'REGION_CODE', 'REGION_NAME', 'PRICE_EE', 'PRICE_N')
plan_fact <- merge(fcst_data, fact_data_grouped,
by = c('PCODE', 'REGION_CODE'), all.x = TRUE, sort = TRUE)
quality <- na.omit(plan_fact)
quality$error_M <- quality$PRICE_N - quality$SVNC_M_FACT
quality$abs_error_M <- abs(quality$PRICE_N - quality$SVNC_M_FACT)
quality$pcnt_error_M <- quality$abs_error_M / quality$SVNC_M_FACT * 100
quality$MAE_M <- mean(quality$abs_error_M)
quality$MAE_pcnt_M <- mean(quality$pcnt_error_M)
quality$median_error_M <- median(quality$abs_error_M)
quality$pcnt_median_error_M <- median(quality$pcnt_error_M)
quality$error_EE <- quality$PRICE_EE - quality$SVNC_EE_FACT
quality$abs_error_EE <- abs(quality$PRICE_EE - quality$SVNC_EE_FACT)
quality$pcnt_error_EE <- quality$abs_error_EE / quality$SVNC_EE_FACT * 100
quality$MAE_EE <- mean(quality$abs_error_EE)
quality$MAE_pcnt_EE <- mean(quality$pcnt_error_EE)
quality$median_error_EE <- median(quality$abs_error_EE)
quality$pcnt_median_error_EE <- median(quality$pcnt_error_EE)
View(quality)
library(rsconnect)
#Sys.setenv(http_proxy = "http://i.zemskov:GrandPik9@localhost:8080/")
library(RCurl)
options(RCurlOptions = list(proxy = "http://i.zemskov:GrandPik9@localhost:8080"))
setAccountInfo(name = "123a", token = "E6A47DF5869B6618EF9691E36B33F5F0",
secret = "TRkD7LNpmgL9MvTbwcreHC3IXl11NlSw0elEbibS")
deployApp(appDir = "C:/!zemskov/svnc_forecast/shiny_app", appName = "svnc",
account = "123a")
deployApp(appDir = "C:/!zemskov/svnc_forecast/shiny_app", appName = "svnc",
account = "123a")
deployApp(appDir = "C:/!zemskov/svnc_forecast/shiny_app", appName = "svnc",
account = "123a")
deployApp(appDir = "C:/!zemskov/svnc_forecast/shiny_app", appName = "svnc",
account = "123a")
deployApp(appDir = "C:/!zemskov/svnc_forecast/shiny_app", appName = "svnc",
account = "123a")
load(file = 'data_sources/DPG_GP_INFO.RData')
deployApp(appDir = "C:/!zemskov/svnc_forecast/shiny_app", appName = "svnc",
account = "123a")
deployApp(appDir = "C:/!zemskov/svnc_forecast/shiny_app", appName = "svnc",
account = "123a")
deployApp(appDir = "C:/!zemskov/svnc_forecast/shiny_app", appName = "svnc",
account = "123a")
deployApp(appDir = "C:/!zemskov/svnc_forecast/shiny_app", appName = "svnc",
account = "123a")
library(RCurl)
options(RCurlOptions = list(proxy = "http://i.zemskov:GrandPik9@localhost:8080"))
setAccountInfo(name = "123a", token = "E6A47DF5869B6618EF9691E36B33F5F0",
secret = "TRkD7LNpmgL9MvTbwcreHC3IXl11NlSw0elEbibS")
deployApp(appDir = "C:/!zemskov/svnc_forecast/shiny_app", appName = "svnc",
account = "123a")
options(RCurlOptions = list(proxy = "https://i.zemskov:GrandPik9@localhost:8080"))
setAccountInfo(name = "123a", token = "E6A47DF5869B6618EF9691E36B33F5F0",
secret = "TRkD7LNpmgL9MvTbwcreHC3IXl11NlSw0elEbibS")
deployApp(appDir = "C:/!zemskov/svnc_forecast/shiny_app", appName = "svnc",
account = "123a")
?options
